# AI Hedge Fund Simulation

![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

This project simulates a multi-agent hedge fund where different AI agents, each embodying a distinct investment philosophy (e.g., Warren Buffett, Cathie Wood, Ben Graham), analyze market data and propose trading signals. A final Portfolio Manager agent synthesizes these recommendations, considers risk constraints, and makes final trading decisions.

The system leverages the **LangGraph** framework for defining the agent workflow and **LangChain** for interacting with various Large Language Models (LLMs), including commercial APIs (OpenAI, Anthropic, Groq, etc.) and **local models via Ollama**.

## Key Features

*   **Multi-Agent System:** Utilizes LangGraph to orchestrate analysis from diverse AI agents running in parallel or sequence.
*   **Diverse Investment Philosophies:** Includes agents modeled after famous investors (Buffett, Munger, Graham, Fisher, Ackman, Wood, Druckenmiller) and factor-based programmatic analysts (Fundamentals, Valuation, Technicals, Sentiment).
*   **Flexible LLM Support:** Easily configure and use different LLMs via API (OpenAI, Anthropic, Groq, Google Gemini, DeepSeek) or run locally using **Ollama** (Llama3, Mistral, Qwen, Phi3, etc.).
*   **Hybrid Approach:** Combines programmatic analysis (technical indicators, fundamental ratios, valuation models) with qualitative reasoning generated by LLMs.
*   **Modular Design:** Code is organized into agents, LLM utilities, display functions, progress tracking, and graph definition for better maintainability.
*   **Risk Management:** Includes a dedicated agent to calculate position size limits based on portfolio equity and predefined rules.
*   **Backtesting Framework:** Simulate strategy performance over historical data using `backtester.py`.
*   **Interactive Configuration:** Uses `questionary` for easy selection of analysts and LLM models via the terminal.
*   **Visualization:** Option to generate a PNG image of the agent workflow graph.
*   **Robustness:** Improved error handling, data validation, and calculation safety across modules.

## Architecture

The simulation follows this general workflow:

1.  **Initialization (`main.py` / `backtester.py`):**
    *   Parse command-line arguments (tickers, dates, capital).
    *   User selects desired **Analysts** and **LLM Model/Provider** via interactive prompts.
    *   Check API keys / Ollama connection.
    *   Compile the LangGraph workflow (`create_workflow`) based on selections.
    *   Set up the initial portfolio state.
2.  **LangGraph Execution (`run_hedge_fund` function):**
    *   The compiled graph (`agent_graph`) is invoked with the initial state.
    *   **`start_node`**: Begins the process.
    *   **Analyst Nodes (Parallel):** Each selected agent function (e.g., `ben_graham_agent`, `technicals_agent`) executes:
        *   Fetches necessary data (prices, financials, news, etc.) via `tools/api.py`.
        *   Performs quantitative analysis and/or prepares data for LLM.
        *   If required, calls the selected LLM via `llm/llm.py` (`call_llm`) for qualitative reasoning and signal generation, using structured Pydantic output.
        *   Updates `progress` and stores its signal/reasoning in `state["data"]["analyst_signals"]`.
    *   **`risk_management_agent`**: Runs after analysts. Fetches latest prices, calculates portfolio equity, and determines position sizing limits (`max_additional_value_allocation`, `max_buy_shares`) per ticker. Stores results in `state["data"]["risk_analysis"]`.
    *   **`portfolio_management_agent`**: Runs after risk management.
        *   Synthesizes all analyst signals and risk limits.
        *   Calls the selected LLM via `call_llm` with a highly constrained prompt to generate final trading decisions (`action`, `quantity`) for each ticker, adhering strictly to risk/cash/margin limits. Uses structured Pydantic output.
        *   Adds the final decision message to `state["messages"]`.
    *   **`END`**: The graph execution finishes, returning the final state.
3.  **Output / Backtest Step:**
    *   **`main.py`**: Parses the final message from the portfolio manager and displays the results using `utils/display.print_trading_output`.
    *   **`backtester.py`**: Parses the final message, executes simulated trades using `execute_trade`, updates the portfolio state, calculates daily performance, logs results via `utils/display.print_backtest_results`, and repeats for the next day. Finally, analyzes and plots overall performance.

## Technology Stack

*   **Core:** Python 3.10+
*   **Orchestration:** LangGraph
*   **LLM Interaction:** LangChain, `langchain-openai`, `langchain-anthropic`, `langchain-groq`, `langchain-google-genai`, `langchain-deepseek`, `langchain-community` (for Ollama)
*   **Local LLMs:** Ollama
*   **UI/Interaction:** `questionary`, `rich`, `colorama`
*   **Data/Calculation:** `pandas`, `numpy` (implicitly via tools/agents)
*   **Utilities:** `python-dotenv`, `pydantic`, `tabulate`
*   **Plotting:** `matplotlib` (for backtester)
*   **(Optional for Graph Viz):** `pygraphviz` or access to Mermaid API

## Setup Instructions

1.  **Clone Repository:**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Create Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    # Activate (Linux/macOS)
    source venv/bin/activate
    # Activate (Windows)
    .\venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Install Ollama (for Local LLMs):**
    *   Follow the instructions on [https://ollama.com/](https://ollama.com/) to download and run Ollama on your system.

5.  **Pull Ollama Models:**
    *   Download the models you want to use via the Ollama CLI. Examples:
        ```bash
        ollama pull llama3:8b       # Or llama3:70b
        ollama pull mistral
        ollama pull qwen:7b
        ollama pull deepseek-coder
        ollama pull phi3
        # Add any other models you want to make available
        ```

6.  **Configure Environment Variables (`.env` file):**
    *   Create a file named `.env` in the project root directory.
    *   Add necessary API keys for any commercial LLM services you intend to use.
    *   Configure the Ollama base URL (usually defaults are fine).
    *   *Example `.env` content:*
        ```dotenv
        # --- Required for Commercial Services (Optional) ---
        # OPENAI_API_KEY="sk-..."
        # ANTHROPIC_API_KEY="sk-..."
        # GROQ_API_KEY="gsk_..."
        # DEEPSEEK_API_KEY="sk-..."
        # GOOGLE_API_KEY="AIza..." # For Gemini

        # --- Required for Ollama ---
        OLLAMA_BASE_URL="http://localhost:11434" # Default Ollama URL

        # --- Required for Data Tools (Example - ADD YOUR KEYS) ---
        # FMP_API_KEY="YOUR_FINANCIAL_MODELING_PREP_KEY" # If using FMP in tools/api.py
        # OTHER_API_KEYS="..." # Add keys for any other data sources used in tools/api.py
        ```
    *   **Important:** Ensure the API keys for any data sources used in `tools/api.py` are correctly set.

7.  **Configure Available Models (`llm/models.py`):**
    *   Open the `llm/models.py` file.
    *   Review the `AVAILABLE_MODELS` list.
    *   **For Ollama:** Ensure the `model_name` for Ollama entries exactly matches the model name you used in the `ollama pull` command (e.g., `"llama3:8b"`, `"mistral"`). Add or remove entries as needed.
    *   Add/Remove entries for other providers (OpenAI, Anthropic, etc.) as desired.

## Usage

### Single Simulation Run (`main.py`)

This script runs the simulation once for the specified tickers and date range, outputting the final trading decisions.

```bash
python main.py --tickers <TICKER1,TICKER2,...> [options]

Required Argument:

--tickers: Comma-separated list of stock symbols (e.g., AAPL,MSFT,NVDA).

Optional Arguments:

--start-date <YYYY-MM-DD>: Analysis start date (defaults to 3 months before end date).

--end-date <YYYY-MM-DD>: Analysis end date (defaults to today).

--initial-cash <amount>: Starting cash for the portfolio (default: 100000.0).

--margin-requirement <ratio>: Margin requirement for short selling (e.g., 0.5 for 50%, default: 0.0).

--show-reasoning: Display detailed reasoning output from each agent.

--show-agent-graph [filename.png]: Generate a PNG image of the agent workflow (defaults to ai_hedge_fund_graph.png).

Example:

python main.py --tickers GOOGL,AMZN --end-date 2023-12-31 --show-reasoning
Use code with caution.
Bash
You will be interactively prompted to select the analysts and the LLM model to use for the run.

Backtesting Simulation (backtester.py)
This script runs the simulation day-by-day over a historical period, executing trades and tracking portfolio performance.

python backtester.py --tickers <TICKER1,TICKER2,...> --start-date <YYYY-MM-DD> [options]
Use code with caution.
Bash
Required Arguments:

--tickers: Comma-separated list of stock symbols.

--start-date <YYYY-MM-DD>: Backtest start date.

Optional Arguments:

--end-date <YYYY-MM-DD>: Backtest end date (defaults to today).

--initial-capital <amount>: Starting cash (default: 100000.0).

--margin-requirement <ratio>: Margin requirement for short selling (default: 0.0).

Example:

python backtester.py --tickers TSLA,NIO,RIVN --start-date 2023-01-01 --end-date 2023-06-30 --initial-capital 50000 --margin-requirement 0.5
Use code with caution.
Bash
You will be interactively prompted to select the analysts and the LLM model to use for the backtest. The script will output daily progress and final performance metrics, including a plot of the portfolio value.

Configuration Notes
.env File: Essential for API keys and the Ollama URL. Keep this file secure and do not commit it to public repositories.

llm/models.py: This file is the central registry for LLMs. Accuracy here is crucial for the model selection prompts and for llm/llm.py to function correctly. Ensure Ollama model names match exactly what ollama list shows.

tools/api.py: This file likely contains functions to fetch market data. Ensure it's correctly implemented and any necessary API keys are configured in .env. Its reliability directly impacts the simulation results.

Agent Thresholds: Thresholds used within programmatic agents (like fundamentals, technicals, or the quantitative parts of investor agents) can be tuned directly within their respective Python files for different market conditions or analysis styles.

Current Status & Limitations
Status: The framework provides functional simulation and backtesting capabilities. It supports multiple LLM providers, including local models via Ollama. Agent logic incorporates specific investor philosophies with improved quantitative analysis and LLM prompting. Robustness and error handling have been enhanced.

Limitations:

Simulation Only: Does not execute real trades.

Market Data: Relies on available data from tools/api.py. Data quality, granularity (daily), and availability can vary. Does not model market microstructure.

Execution Model: Backtester assumes trades execute at the closing price of the decision day. No slippage or commissions are modeled.

Risk Management: Current risk model is basic (percentage limit). Does not include advanced measures (VaR, CVaR, factor exposures) or dynamic adjustments. No margin call simulation.

LLM Dependency: Quality of reasoning and decisions from LLM-driven agents heavily depends on the chosen model, prompt quality, and the inherent limitations of LLMs (hallucinations, lack of true understanding). Requires careful prompt engineering and result validation.

API Costs/Limits: Using commercial LLM APIs can incur costs and be subject to rate limits. tools/api.py data sources may also have limits/costs.

Roadmap / Future Improvements
Data:

Integrate more diverse data sources (news APIs, sentiment APIs, alternative data, more fundamental providers).

Support for intraday data and backtesting.

Cache frequently requested API data.

Agents:

Develop more specialized agents (e.g., sector-specific, macro-economic, event-driven).

Implement agents using more quantitative factor models (e.g., Fama-French).

Enable agents to use more complex tools (web search via Tavily/SerpAPI, code execution for custom analysis).

Explore agent learning/adaptation based on performance (complex).

Implement agent-to-agent communication/debate before final decision.

Risk Management:

Implement VaR / CVaR calculations.

Dynamic position sizing based on volatility, correlation, or conviction score.

Simulate margin calls.

Portfolio Construction:

Introduce optimization techniques (Mean-Variance, Risk Parity) post-signal generation.

Consider portfolio-level constraints (e.g., sector exposure).

LLM Interaction:

Utilize LLM function calling for more reliable tool use and structured data retrieval/generation.

Experiment with fine-tuned LLMs for specific financial analysis tasks.

Add more sophisticated error handling and retries for LLM calls.

Backtesting:

Model slippage and commission costs.

Implement intraday backtesting capabilities.

Add more performance metrics (Calmar Ratio, Omega Ratio, Sortino Ratio, rolling Sharpe).

Develop parameter optimization loops for agent thresholds/weights.

User Interface:

Create a web-based UI (Streamlit or Gradio) for easier configuration, execution, and result visualization.

Deployment:

Dockerize the application for easier deployment.

Explore options for running simulations on cloud platforms.

Contributing
Contributions are welcome! Please feel free to submit issues or pull requests. (Add more specific guidelines if desired).

License
This project is licensed under the MIT License - see the LICENSE file for details. 
